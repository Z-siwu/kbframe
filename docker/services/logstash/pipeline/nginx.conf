# 接收/监听
input {
    beats {
        port => 5044
    }

    kafka {
        bootstrap_servers => "192.168.0.1:9092"
        topics => ["filebeat"]
        # decroate_events   => true
        # group_id => "consumer-test"
        # （初始消费，相当于from beginning，不设置，相当于是监控启动后的kafka的消息生产）
        auto_offset_reset => "latest"
        codec => "json"
    }
}

# 过滤
filter{
    if [fileset][module] == "nginx" {
       if [fileset][name] == "error" {
            grok {
                match => { "message" => ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
                remove_field => "message"
            }
            date {
                match => [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
                remove_field => "[nginx][error][time]"
            }
        }
        else if [fileset][name] == "access" {
            json {
                source => "message"
                skip_on_invalid_json => true
            }
        }
    }
}

# 输出
output {
    if [fileset][module] == "nginx" {
       if [fileset][name] == "error" {
            elasticsearch {
                hosts => ["elasticsearch:9200"]
                index => "%{[@metadata][beat]}-%{[@metadata][version]}-nginx-error-log-%{+YYYY.MM.dd}"
                manage_template => false
            }
        }
        else if [fileset][name] == "access" {
            elasticsearch {
                hosts => ["elasticsearch:9200"]
                index => "%{[@metadata][beat]}-%{[@metadata][version]}-nginx-access-log-%{+YYYY.MM.dd}"
                template_name => "nginx"
                template_overwrite => true
            }
        }
    }
 }